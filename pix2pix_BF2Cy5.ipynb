{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']=\"3,4,5\"\n",
    "import torch,torchvision\n",
    "import matplotlib\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import cv2\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ed109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1619cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = torch.load('G_pix2pix_BF2Cy5').module\n",
    "#D = torch.load('D_pix2pix_BF2Cy5').module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73426fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enable cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "G = G.to(device)\n",
    "#D = D.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18983af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#torch.manual_seed(0)\n",
    "#random.seed(0)\n",
    "#np.random.seed(0)\n",
    "\n",
    "model_smp = smp.Unet(\n",
    "    encoder_name='resnet34',        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=None, \n",
    "    encoder_depth = 4, \n",
    "    decoder_channels = [384,192,81,27],# use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=64):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, d, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(d, d * 2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(d * 2)\n",
    "        self.conv3 = nn.Conv2d(d * 2, d * 4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(d * 4)\n",
    "        self.conv4 = nn.Conv2d(d * 4, d * 8, 4, 1, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(d * 8)\n",
    "        self.conv5 = nn.Conv2d(d * 8, 2, 4, 1, 1)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input, label):\n",
    "        x = torch.cat([input, label], 1)\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        x = F.sigmoid(self.conv5(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()\n",
    "        \n",
    "root_path = '/mnt/sdc/cell_images/data/Project_4/Astrocytes/'\n",
    "folders = glob.glob(root_path+\"*/\")\n",
    "folders.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2086cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall = []\n",
    "for i in range(4):\n",
    "    files = glob.glob(folders[i]+'/*.tif')\n",
    "    df = pd.DataFrame(files)\n",
    "    df.columns = ['Path']\n",
    "    df_spt = df['Path'].str.split(r'/|\\.| |\\(|\\)',expand = True)\n",
    "    col_len = len(df_spt.columns)\n",
    "    df['Folder'] =df_spt[7].str.strip()\n",
    "    df['Row'] = df_spt[13].str.strip()\n",
    "    df['Column'] = df_spt[15].str.strip()\n",
    "    df['Field'] = df_spt[17].str.strip()\n",
    "    df['Identification'] = df['Row'].str.cat(df[['Column', 'Field']], sep='-')\n",
    "    df['Colour'] = df_spt[col_len - 5].str.strip()\n",
    "    df['Channel'] = df_spt[col_len - 3].str.strip()\n",
    "    df = df.sort_values(by = ['Folder','Identification','Colour'])\n",
    "    df_overall.append(df)\n",
    "\n",
    "df = pd.concat(df_overall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0517b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2pixDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, transform=None,mode = \"train\"):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        length = int(len(self.dataframe)/5)\n",
    "        return length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row_FITC = self.dataframe.iloc[index*5]\n",
    "        row_dsRed = self.dataframe.iloc[index*5+1]\n",
    "        row_Cy5 = self.dataframe.iloc[index*5+2]\n",
    "        row_BF = self.dataframe.iloc[index*5+3]\n",
    "        row_DAPI = self.dataframe.iloc[index*5+4]\n",
    "\n",
    "        image = Image.open(row_BF[\"Path\"])\n",
    "        pre_transform = transforms.ToTensor()\n",
    "        #img_FITC = pre_transform(Image.open(row_FITC[\"Path\"]))\n",
    "        #img_dsRed = pre_transform(Image.open(row_dsRed[\"Path\"]))\n",
    "        img_Cy5 = pre_transform(Image.open(row_Cy5[\"Path\"]))\n",
    "        #img_DAPI = pre_transform(Image.open(row_DAPI[\"Path\"]))\n",
    "        \n",
    "        label = torch.stack([img_Cy5],dim = 1)\n",
    "        \n",
    "        label = label.squeeze(0)\n",
    "\n",
    "        # Resize\n",
    "        #resize = transforms.Resize(size=(512, 512))\n",
    "        #image,label  = resize(image),resize(label)\n",
    "        #mask is already 512*512\n",
    "        #mask = resize(mask)\n",
    "\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f007d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rough normalization on val set, how could we give better normalization?\n",
    "mean_BF = torch.tensor([2355.3508])\n",
    "std_BF = torch.tensor([353.2483])\n",
    "mean_label = torch.tensor([2185.792])\n",
    "std_label = torch.tensor([2148.2190])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a6909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFromSubset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, transform=None, mode = \"train\"):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.subset[index]\n",
    "        pre_transform = transforms.ToTensor()\n",
    "        image = pre_transform(image)\n",
    "        resize = transforms.Resize(size=(600, 600))\n",
    "        image,label  = resize(image).float(),resize(label).float()\n",
    "        if self.mode ==\"train\":\n",
    "                    # Random crop\n",
    "            i, j, h, w = transforms.RandomCrop.get_params(\n",
    "                image, output_size=(512, 512))\n",
    "            image = TF.crop(image, i, j, h, w)\n",
    "            label = TF.crop(label, i, j, h, w)\n",
    "\n",
    "            # Random horizontal flipping\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.hflip(image)\n",
    "                label = TF.hflip(label)\n",
    "\n",
    "            # Random vertical flipping\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.vflip(image)\n",
    "                label = TF.vflip(label)\n",
    "            \n",
    "        post_transform_image = transforms.Compose([transforms.CenterCrop(512),\n",
    "                                            transforms.Normalize(mean_BF,std_BF)\n",
    "                                                  ])\n",
    "        post_transform_label = transforms.Compose([transforms.CenterCrop(512),\n",
    "                                            transforms.Normalize(mean_label,std_label)])\n",
    "        image = post_transform_image(image)\n",
    "        label = post_transform_label(label)\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e062e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Pix2pixDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(dataset)\n",
    "n_train = int(0.9*n)\n",
    "n_val = int(0.05*n)\n",
    "n_test = n-n_train-n_val\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "train_data = DatasetFromSubset(train_set,mode = \"train\")\n",
    "val_data = DatasetFromSubset(val_set, mode = \"val\")\n",
    "test_data = DatasetFromSubset(test_set,mode = \"val\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4,shuffle=True,pin_memory = True)  # <1>\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=4,shuffle=True,pin_memory = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=4,shuffle=True,pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_image = transforms.ToPILImage()\n",
    "inv_normalize_BF = transforms.Normalize(\n",
    "    mean=[-2355.3508/353.2483],\n",
    "    std=[1/353.2483]\n",
    ")\n",
    "inv_normalize_label = transforms.Normalize(\n",
    "    mean=-mean_label/std_label,\n",
    "    std = 1/std_label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8ce5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = model_smp\n",
    "D = discriminator()\n",
    "#G.weight_init(mean=0.0, std=0.02)\n",
    "D.weight_init(mean=0.0, std=0.02)\n",
    "G = torch.nn.DataParallel(G)\n",
    "G = G.cuda()\n",
    "D = torch.nn.DataParallel(D)\n",
    "D = D.cuda()\n",
    "BCE_loss = nn.BCELoss().cuda()\n",
    "L1_loss = nn.L1Loss().cuda()\n",
    "G_optimizer = torch.optim.Adam(G.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "D_optimizer = torch.optim.Adam(D.parameters(), lr=1e-5, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e703c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e5924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x ,y = test_data[13]\n",
    "title = [\"Cy5\"]\n",
    "with torch.no_grad():\n",
    "    inv_y = inv_normalize_label(y)\n",
    "    fig, ax = plt.subplots(2,5,gridspec_kw={'width_ratios': [1, 1, 1,1,1]},figsize=(70, 25))\n",
    "    #plt.tight_layout()\n",
    "    #ax1 = plt.subplot2grid((2,5),(0,0),rowspan = 2)\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Brightfield Image\",fontsize=50)\n",
    "    plt.imshow(to_image(10*inv_normalize_BF(x).type(torch.int16).squeeze(0)+10000),cmap = 'cividis')\n",
    "    for i in range(1):\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.axis('off')\n",
    "        plt.title('True '+title[i],fontsize=36)\n",
    "        plt.imshow(to_image(inv_y[i].type(torch.int16).squeeze(0)))\n",
    "    for i in range(1):\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.title('Generated '+title[i],fontsize=36)\n",
    "        plt.imshow(to_image(inv_normalize_label(G(x.unsqueeze(0).cuda()).squeeze(0))[i].type(torch.int16)))\n",
    "plt.savefig('/mnt/sdd/MSc_projects/yizhang/projects/project_test/BF2Cy5_pix2pix/Plot at epoch 0_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9d6119",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = {}\n",
    "train_hist['D_losses'] = []\n",
    "train_hist['G_losses'] = []\n",
    "train_hist['per_epoch_ptimes'] = []\n",
    "train_hist['total_ptime'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd7140",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_n_iter = 0\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79682f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch+1, 100):\n",
    "    # set models to train mode\n",
    "    D_losses = []\n",
    "    G_losses = []\n",
    "    G.train()\n",
    "    D.train()\n",
    "    print(epoch)\n",
    "    pbar = tqdm(enumerate(train_loader),\n",
    "                total=len(train_loader),bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "    x_test,y_test = test_data[13]\n",
    "    inv_y = inv_normalize_label(y_test)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, data in pbar:  \n",
    "        imgs , labels = data\n",
    "        x = imgs.cuda()\n",
    "        y = labels.cuda()\n",
    "        prepare_time = start_time-time.time()\n",
    "        #print('iteration '+str(i))\n",
    "        #D first\n",
    "        D.zero_grad()\n",
    "        D_result = D(x,y)\n",
    "        D_real_loss = BCE_loss(D_result, torch.ones(D_result.size()).cuda())\n",
    "        G_result = G(x)\n",
    "        D_result = D(x, G_result)\n",
    "        D_fake_loss = BCE_loss(D_result, torch.zeros(D_result.size()).cuda())\n",
    "        D_train_loss = (D_real_loss + D_fake_loss) * 0.5\n",
    "        D_train_loss.backward()\n",
    "        D_optimizer.step()\n",
    "        \n",
    "        train_hist['D_losses'].append(D_train_loss.data)\n",
    "        D_losses.append(D_train_loss.data)\n",
    "        #G then\n",
    "        G.zero_grad()\n",
    "        G_result = G(x)\n",
    "        D_result = D(x, G_result).squeeze()\n",
    "        G_train_loss = BCE_loss(D_result,torch.ones(D_result.size()).cuda())+ 100 * L1_loss(G_result, y)\n",
    "        G_train_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        train_hist['G_losses'].append(G_train_loss.data)\n",
    "        G_losses.append(G_train_loss.data)\n",
    "        \n",
    "        if i%50 == 0:\n",
    "            #print('Plot at epoch '+str(epoch+1)+' steps '+str(i))\n",
    "            #show sample image for specific steps\n",
    "            with torch.no_grad():\n",
    "                fig, ax = plt.subplots(2,5,gridspec_kw={'width_ratios': [1, 1, 1,1,1]},figsize=(70, 25))\n",
    "                #plt.tight_layout()\n",
    "                #ax1 = plt.subplot2grid((2,5),(0,0),rowspan = 2)\n",
    "                plt.subplot(1,3,1)\n",
    "                plt.title(\"Brightfield Image\",fontsize=50)\n",
    "                plt.imshow(to_image(10*inv_normalize_BF(x_test).type(torch.int16).squeeze(0)+10000),cmap = 'cividis')\n",
    "                for j in range(1):\n",
    "                    plt.subplot(1,3,2)\n",
    "                    plt.title('True '+title[j],fontsize=36)\n",
    "                    plt.imshow(to_image(inv_y[j].type(torch.int16).squeeze(0)))\n",
    "                for j in range(1):\n",
    "                    plt.subplot(1,3,3)\n",
    "                    plt.title('Generated '+title[j],fontsize=36)\n",
    "                    plt.imshow(to_image(inv_normalize_label(G(x_test.unsqueeze(0).cuda())).squeeze(0)[j].type(torch.int16)))\n",
    "                plt.savefig('/mnt/sdd/MSc_projects/yizhang/projects/project_test/BF2Cy5_pix2pix/'+'Plot at epoch '+str(epoch)+' steps '+str(i))\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        # compute computation time and *compute_efficiency*\n",
    "        process_time = start_time-time.time()-prepare_time\n",
    "        compute_efficiency = process_time/(process_time+prepare_time)\n",
    "        pbar.set_description(\n",
    "            f'Compute efficiency: {compute_efficiency:.4f}, ' \n",
    "            f'Dloss:{D_train_loss.item():.4f}, Gloss: {G_train_loss.item():.4f},  epoch: {epoch}/{30}')\n",
    "        \n",
    "    epoch_time = time.time()\n",
    "    per_epoch_ptime = epoch_time-start_time\n",
    "    print(per_epoch_ptime)\n",
    "    torch.save(G,'G_pix2pix_BF2Cy5')\n",
    "    torch.save(D,'D_pix2pix_BF2Cy5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c51ec2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
